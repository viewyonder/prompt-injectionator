# 1. Academic Papers

### Foundational Papers (2023-2025)

**Core Research:**

* **[Prompt Injection attack against LLM-integrated Applications](https://arxiv.org/abs/2306.05499)** (Liu et al., 2023)
  * Seminal work defining prompt injection taxonomy
  * Covers both direct and indirect injection attacks
  * Provides formal threat model framework
* **[Formalizing and Benchmarking Prompt Injection Attacks and Defenses](https://www.usenix.org/conference/usenixsecurity24/presentation/liu-yupei)** (USENIX Security 2024)
  * Comprehensive benchmark framework
  * Formal definitions and evaluation metrics
  * Open-source evaluation tools
* **[AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents](https://arxiv.org/abs/2406.13352)** (NeurIPS 2024)
  * Dynamic testing environment for LLM agents
  * Focus on tool-using agents and indirect attacks
  * Extensible framework for new attack/defense research

**Specialized Attack Vectors:**

* **DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks** (Liu et al., 2025)
  * Game theory approach to detection
  * Advanced mathematical modeling
  * Available in Open-Prompt-Injection repository
* **Poisoned RAG** (2024)
  * RAG-specific injection techniques
  * Demonstrates effectiveness with minimal poisoned data
  * Critical for document-based applications

### Research Gaps to Investigate:

* Multi-modal injection attacks (image, audio, video)
* Chain-of-thought manipulation
* Few-shot learning exploitation
* Cross-language injection techniques
