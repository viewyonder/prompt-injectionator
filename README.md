# Prompt Injectionator
An LLM security tool to educate, test, detect, and mitigate prompt injections against LLM-based applications.

By [Steve Chambers](https://www.linkedin.com/in/steviechambers/)

> [!NOTE]
> 2025-08-20 This is a prototype application current for educational purposes. Future milestones will ship a usable Web UI and Terminal CLI.
